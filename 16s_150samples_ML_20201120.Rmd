---
title: 'Machine'
author: "Binbin Zhao"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output:
  html_document:
    number_sections: no
    toc: yes
    toc_depth: 6
    toc_float: true
    self_contained: true
    thumbnails: true
    lightbox: true
    gallery: true
    use_bookdown: false
    highlight: haddock
type: post
description: modified from https://github.com/rlbarter
---

# Getting set up


First we need to load some libraries: `tidymodels` and `tidyverse`. 

```{r, echo=F, results='hide', message=F, warning=F,include=F}
# load the relevant tidymodels libraries
library(phyloseq)
library(microbiome)
library(tidyverse)
library(compositions)
library(knitr)
library(ggpubr)
library(DT)
library(ComplexHeatmap)
library(hsstan)
library(healthcareai)
library(animalcules)
library("yardstick")
library(pROC)
source("src/pipline_function_16s.r" )
`%+%` <- function(a,b) {paste0(a,b)}
# load the dataset
```

```{r include=F}
seed = 100
dir.create("output/", recursive = TRUE)
dir.create("output/table", recursive = TRUE)
dir.create("output/figure", recursive = TRUE)
# load phyloseq
phy <- readRDS("data/SixHosp_16S_150subjects_AD_aMCI_AD_based_on_criteria_Above20percentMissingDeleted_Age5080_PCA_combined095_20201102_with3Omics.rds")
sample_names(phy) <- gsub("-", "_", sample_names(phy))
```


```{r echo=F, results='hide', message=F, warning=F,include=F}
# convert ASV sequence to ASV ID
phy <- convertSeq2ASV(phy)
# check rows
if (taxa_are_rows(phy) ==F) phy <- t(phy)

# color set
mycols <<- c(
  "#e6194b", "#3cb44b", "#4363d8", "#ffe119", "#f58231",
  "#911eb4", "#46f0f0", "#f032e6", "#bcf60c", "#fabebe",
  "#008080", "#e6beff", "#9a6324", "#fffac8", "#800000",
  "#aaffc3", "#808000", "#ffd8b1", "#000075", "#808080",
  "#000000"
)

phy <- ordered_phy(phy = phy,group = "Diagnosis")
metat <- sample_data(phy) %>% data.frame()
```


```{r echo=F, results='hide', message=F, warning=F,include=F}

abbreviate_taxa_names <- function (names, nlet = 3, totl = 11, sep = "__", seconditem = F)
{   
   # browser()
    names <- base::make.names(names, unique = FALSE)
    names <- gsub("\\.[\\.]+", ".", names)
    names <- gsub("\\.$", "", names)
    names <- lapply(strsplit(names, "\\."), function(x) {
        if (length(x) > 1) {
            x
        }
        else {
            x
        }
    })
    names <- unlist(lapply(names, function(x) {
        if (length(x) > 1) {
            # paste(x[c(1, 2, 3)]),
          sec <- paste(x[c(1)], "_g", sep = "")
          firs <- paste(x[c(2)], "_s", sep = "")
          third <- paste("_",x[c(length(x))] ,sep = "")
          paste("f", sec, firs,third, sep = sep)
        }
        else {
            x
        }
    }))
    return(names)
}

x <- c("Laccaria laccata fsffsdf ", "Meliniomyces bicolor fsfafd 123")

```

# Data filter

```{r }
phy_core_all <- core(phy, detection = 0.0005, prevalence = .1)
phy_core_all
```


# AD vs NC

```{r }
batch_name <- "ADvsNC"
metat_group <- subset(metat, Diagnosis != "aMCI")
phy_core <- phy_core_all
sample_data(phy_core) <- metat_group
phy_core <- microbiome::transform(phy_core, "clr") # clr transformation
otu_tab <- scale(t(abundances(phy_core))) %>% data.frame()
asv_to_bact <-tax_table(phy_core) %>% data.frame()
asv_to_bact <- paste(asv_to_bact$Family, asv_to_bact$Genus, row.names(asv_to_bact), sep = "")
asv_to_bact <- abbreviate_taxa_names(asv_to_bact)
colnames(otu_tab) <- asv_to_bact
otu_tab$SampleID <- row.names(otu_tab)
new_table <- dplyr::select(metat_group, "sample_GV", "Diagnosis", "Gender", "Age")
new_otu_table <- merge(x = otu_tab, y = new_table, by.x = "SampleID", by.y = "sample_GV", all=TRUE) %>%
                dplyr::select("SampleID", "Diagnosis", "Gender", "Age", everything()) %>% subset(select = -SampleID)
new_otu_table$Diagnosis <- as.factor(new_otu_table$Diagnosis)
new_otu_table$Diagnosis <- relevel(new_otu_table$Diagnosis ,str_split(batch_name, pattern = "vs")[[1]][1])
write.table(new_otu_table, file = "output/table/AD_vs_NC_tss.csv", sep = ",", row.names = FALSE)
```


## Train biomarker using package hsstan

```{r warning=F, message=F}
 
options(mc.cores=10)
hs.base <- hsstan(new_otu_table, Diagnosis ~ Age + Gender, penalized = "")
hs.biom <- hsstan(new_otu_table, Diagnosis ~ Age + Gender, penalized=colnames(new_otu_table)[4:length(new_otu_table)])
sampler.stats(hs.base)
sampler.stats(hs.biom)
loo(hs.base)
loo(hs.biom)

set.seed(1)
folds <- caret::createFolds(new_otu_table$Diagnosis, k=10, list=FALSE)
cv.base <- kfold(hs.base, folds=folds)
cv.biom <- kfold(hs.biom, folds=folds)
round(posterior_performance(cv.base), 2)
round(posterior_performance(cv.biom), 2)
sel.biom <- projsel(hs.biom)
DT::datatable(sel.biom)
```



## Easy Machine Learning using package healthcareai

```{r warning=F, message=F}
asv_select <- sel.biom$var[3:length(sel.biom$var)]
all_otu_table <- new_otu_table
new_otu_table <- dplyr::select(new_otu_table, "Diagnosis", asv_select)

```

```{r warning=F, message=F}
quick_models <- machine_learn(new_otu_table, outcome = Diagnosis, positive_class = str_split(batch_name, pattern = "vs")[[1]][1])
predictions <- predict(quick_models, outcome_groups = TRUE)
plot(predictions)
pdf(paste("output/figure/",batch_name, "_easy_machine_learning_predictions.pdf", sep = ""), width = 9, height = 6)
plot(predictions)
dev.off()
importance_var <- get_variable_importance(quick_models)
plot(importance_var)
pdf(paste("output/figure/",batch_name, "_easy_machine_learning_variable_importance.pdf", sep = ""), width = 9, height = 7)
plot(importance_var)
dev.off()
write.csv(importance_var, file = "output/table/AD_vs_NC_easy_variable_importance.csv", row.names = FALSE)
write.csv(predictions, file = "output/table/AD_vs_NC_easy_predictions.csv", row.names = FALSE)
```

#### Confusion matrix and ROC

```{r }
predictions$predicted_group <- relevel(predictions$predicted_group,str_split(batch_name, pattern = "vs")[[1]][1])
cm <- predictions %>% 
  conf_mat(truth = Diagnosis, estimate = predicted_group)
autoplot(cm, type = "heatmap")
pdf(paste("output/figure/",batch_name, "_easy_machine_learning_confusion_matrix.pdf", sep = ""),  width = 8, height = 6)
autoplot(cm, type = "heatmap")
dev.off()
roc_curve <- roc_curve(predictions, Diagnosis,predicted_Diagnosis)
autoplot(roc_curve)
pdf(paste("output/figure/",batch_name, "_easy_machine_learning_roc_curve.pdf", sep = ""))
autoplot(roc_curve)
dev.off()
obj <- roc(predictions$Diagnosis, predictions$predicted_Diagnosis, ci=TRUE, plot =FALSE, levels = c(str_split(batch_name, pattern = "vs")[[1]][1], str_split(batch_name, pattern = "vs")[[1]][2]))
obj$ci
# caret::confusionMatrix(predictions$predicted_group, predictions$Diagnosis, positive = str_split(batch_name, pattern = "vs")[[1]][1])
```

After variable selection using hsstan, The prediction accuracy improved.

## Regular machine learning using package healthcareai

### Data Preparation

```{r warning=F, message=F}

  split_data <- split_train_test(d = new_otu_table,
                               outcome = Diagnosis,
                               p = .8,
                               seed = 84105)

 prepped_training_data <- prep_data(split_data$train, outcome = Diagnosis,
                                   center = TRUE, scale = TRUE,
                                   collapse_rare_factors = FALSE)
# > Training new data prep recipe...
 
models <- tune_models(d = prepped_training_data,
                      outcome = Diagnosis,
                      tune_depth = 25,
                      positive_class = str_split(batch_name, pattern = "vs")[[1]][1],
                      metric = "PR")

evaluate(models, all_models = TRUE)

evalution <- models["glmnet"] 
plot(evalution)
pdf(paste("output/figure/",batch_name, "_regular_machine_learning_evaluation.pdf", sep = ""),width = 8, height = 6)
plot(evalution)
dev.off()
```

### Model Interpretation

#### Interpret

```{r warning=F, message=F, fig.width=8, fig.height=6}
interpretation <- interpret(models)
plot(interpretation)
pdf(paste("output/figure/",batch_name, "_regular_machine_learning_interpret.pdf", sep = ""),width = 8, height = 6)
plot(interpretation)
dev.off()
# > Warning in interpret(models): Interpreting glmnet model, but Random Forest
# > performed best in cross-validation and will be used to make predictions. To use
# > the glmnet model for predictions, extract it with x['glmnet'].

```

#### Variable Importance

```{r warning=F, message=F}
  get_variable_importance <- get_variable_importance(models)
  plot(get_variable_importance)
  pdf(paste("output/figure/",batch_name, "_regular_machine_learning_variable_importance.pdf", sep = ""), width = 9, height = 7)
  plot(get_variable_importance)
  dev.off()

```


### Prediction

```{r warning=F, message=F}
  predictions <-
  predict(models,
          split_data$test,
          outcome_groups = TRUE
  )
# > Prepping data based on provided recipe
importance_var2 <- get_variable_importance(models)
write.csv(importance_var2, file = "output/table/AD_vs_NC_regular_variable_importance.csv", row.names = FALSE)
write.csv(predictions, file = "output/table/AD_vs_NC_regular_predictions.csv", row.names = FALSE)
plot(predictions)
pdf(paste("output/figure/",batch_name, "_regular_machine_learning_predictions.pdf", sep = ""), width = 9, height = 6)
plot(predictions)
dev.off()
```

#### Confusion matrix and ROC

```{r }
predictions$predicted_group <- relevel(predictions$predicted_group,str_split(batch_name, pattern = "vs")[[1]][1])
cm <- predictions %>% 
  conf_mat(truth = Diagnosis, estimate = predicted_group)
autoplot(cm, type = "heatmap")
pdf(paste("output/figure/",batch_name, "_regular_machine_learning_confusion_matrix.pdf", sep = ""),  width = 8, height = 6)
autoplot(cm, type = "heatmap")
dev.off()
roc_curve <- roc_curve(predictions, Diagnosis,predicted_Diagnosis)
autoplot(roc_curve)
pdf(paste("output/figure/",batch_name, "_regular_machine_learning_roc_curve.pdf", sep = ""))
autoplot(roc_curve)
dev.off()
obj <- roc(predictions$Diagnosis, predictions$predicted_Diagnosis, ci=TRUE, plot =FALSE, levels = c(str_split(batch_name, pattern = "vs")[[1]][1], str_split(batch_name, pattern = "vs")[[1]][2]))
obj$ci
# caret::confusionMatrix(predictions$predicted_group, predictions$Diagnosis, positive = str_split(batch_name, pattern = "vs")[[1]][1])

```

### Save

```{r warning=F, message=F}
  save_models(models, file = paste("my_models_",batch_name,".RDS", sep = ""))

```




# aMCI vs NC

```{r }
batch_name <- "aMCIvsNC"
metat_group <- subset(metat, Diagnosis != "AD")
phy_core <- phy_core_all
sample_data(phy_core) <- metat_group
phy_core <- microbiome::transform(phy_core, "clr") # clr transformation
otu_tab <- scale(t(abundances(phy_core))) %>% data.frame()
asv_to_bact <-tax_table(phy_core) %>% data.frame()
asv_to_bact <- paste(asv_to_bact$Family, asv_to_bact$Genus, row.names(asv_to_bact), sep = "")
asv_to_bact <- abbreviate_taxa_names(asv_to_bact)
colnames(otu_tab) <- asv_to_bact
otu_tab$SampleID <- row.names(otu_tab)
new_table <- dplyr::select(metat_group, "sample_GV", "Diagnosis", "Gender", "Age")
new_otu_table <- merge(x = otu_tab, y = new_table, by.x = "SampleID", by.y = "sample_GV", all=TRUE) %>%
                dplyr::select("SampleID", "Diagnosis", "Gender", "Age", everything()) %>% subset(select = -SampleID)
new_otu_table$Diagnosis <- as.factor(new_otu_table$Diagnosis)
new_otu_table$Diagnosis <- relevel(new_otu_table$Diagnosis ,str_split(batch_name, pattern = "vs")[[1]][1])
write.table(new_otu_table, file = "output/table/aMCI_vs_NC_tss.csv", sep = ",", row.names = FALSE)
```


## Train biomarker using package hsstan

```{r warning=F, message=F}
 
options(mc.cores=10)
hs.base <- hsstan(new_otu_table, Diagnosis ~ Age + Gender, penalized = "")
hs.biom <- hsstan(new_otu_table, Diagnosis ~ Age + Gender, penalized=colnames(new_otu_table)[4:length(new_otu_table)])
sampler.stats(hs.base)
sampler.stats(hs.biom)
loo(hs.base)
loo(hs.biom)

set.seed(1)
folds <- caret::createFolds(new_otu_table$Diagnosis, k=10, list=FALSE)
cv.base <- kfold(hs.base, folds=folds)
cv.biom <- kfold(hs.biom, folds=folds)
round(posterior_performance(cv.base), 2)
round(posterior_performance(cv.biom), 2)
sel.biom <- projsel(hs.biom)
DT::datatable(sel.biom)
```


## Easy Machine Learning using package healthcareai


```{r warning=F, message=F}
asv_select <- sel.biom$var[3:length(sel.biom$var)]
all_otu_table <- new_otu_table
new_otu_table <- dplyr::select(new_otu_table, "Diagnosis", asv_select)

```


```{r warning=F, message=F}
quick_models <- machine_learn(new_otu_table, outcome = Diagnosis, positive_class = str_split(batch_name, pattern = "vs")[[1]][1])
predictions <- predict(quick_models, outcome_groups = TRUE)
plot(predictions)
pdf(paste("output/figure/",batch_name, "_easy_machine_learning_predictions.pdf", sep = ""), width = 9, height = 6)
plot(predictions)
dev.off()
importance_var <- get_variable_importance(quick_models)
plot(importance_var)
pdf(paste("output/figure/",batch_name, "_easy_machine_learning_variable_importance.pdf", sep = ""), width = 9, height = 7)
plot(importance_var)
dev.off()
write.csv(importance_var, file = "output/table/aMCI_vs_NC_easy_variable_importance.csv", row.names = FALSE)
write.csv(predictions, file = "output/table/aMCI_vs_NC_easy_predictions.csv", row.names = FALSE)
```

#### Confusion matrix and ROC

```{r }
predictions$predicted_group <- relevel(predictions$predicted_group,str_split(batch_name, pattern = "vs")[[1]][1])
cm <- predictions %>% 
  conf_mat(truth = Diagnosis, estimate = predicted_group)
autoplot(cm, type = "heatmap")
pdf(paste("output/figure/",batch_name, "_easy_machine_learning_confusion_matrix.pdf", sep = ""),  width = 8, height = 6)
autoplot(cm, type = "heatmap")
dev.off()
roc_curve <- roc_curve(predictions, Diagnosis,predicted_Diagnosis)
autoplot(roc_curve)
pdf(paste("output/figure/",batch_name, "_easy_machine_learning_roc_curve.pdf", sep = ""))
autoplot(roc_curve)
dev.off()
obj <- roc(predictions$Diagnosis, predictions$predicted_Diagnosis, ci=TRUE, plot =FALSE, levels = c(str_split(batch_name, pattern = "vs")[[1]][1], str_split(batch_name, pattern = "vs")[[1]][2]))
obj$ci
# caret::confusionMatrix(predictions$predicted_group, predictions$Diagnosis, positive = str_split(batch_name, pattern = "vs")[[1]][1])

```

After variable selection using hsstan, The prediction accuracy improved.

## Regular machine learning using package healthcareai

### Data Preparation

```{r warning=F, message=F}

  split_data <- split_train_test(d = new_otu_table,
                               outcome = Diagnosis,
                               p = .8,
                               seed = 84105)

 prepped_training_data <- prep_data(split_data$train, outcome = Diagnosis,
                                   center = TRUE, scale = TRUE,
                                   collapse_rare_factors = FALSE)
# > Training new data prep recipe...
 
models <- tune_models(d = prepped_training_data,
                      outcome = Diagnosis,
                      tune_depth = 25,
                      positive_class = str_split(batch_name, pattern = "vs")[[1]][1],
                      metric = "PR")

evaluate(models, all_models = TRUE)

evalution <- models["glmnet"] 
plot(evalution)
pdf(paste("output/figure/",batch_name, "_regular_machine_learning_evaluation.pdf", sep = ""),width = 8, height = 6)
plot(evalution)
dev.off()
```

### Model Interpretation

#### Interpret

```{r warning=F, message=F}
 interpretation <- interpret(models)
plot(interpretation)
pdf(paste("output/figure/",batch_name, "_regular_machine_learning_interpret.pdf", sep = ""),width = 8, height = 6)
plot(interpretation)
dev.off()
# > Warning in interpret(models): Interpreting glmnet model, but Random Forest
# > performed best in cross-validation and will be used to make predictions. To use
# > the glmnet model for predictions, extract it with x['glmnet'].

```

#### Variable Importance

```{r warning=F, message=F}
  get_variable_importance <- get_variable_importance(models)
  plot(get_variable_importance)
  pdf(paste("output/figure/",batch_name, "_regular_machine_learning_variable_importance.pdf", sep = ""), width = 9, height = 7)
  plot(get_variable_importance)
  dev.off()
```


### Prediction

```{r warning=F, message=F}
  predictions <-
  predict(models,
          split_data$test,
          outcome_groups = TRUE
  )
# > Prepping data based on provided recipe
importance_var2 <- get_variable_importance(models)
write.csv(importance_var2, file = "output/table/aMCI_vs_NC_regular_variable_importance.csv", row.names = FALSE)
write.csv(predictions, file = "output/table/aMCI_vs_NC_regular_predictions.csv", row.names = FALSE)
plot(predictions)
pdf(paste("output/figure/",batch_name, "_regular_machine_learning_predictions.pdf", sep = ""), width = 9, height = 6)
plot(predictions)
dev.off()

```

#### Confusion matrix and ROC

```{r }
predictions$predicted_group <- relevel(predictions$predicted_group,str_split(batch_name, pattern = "vs")[[1]][1])
cm <- predictions %>% 
  conf_mat(truth = Diagnosis, estimate = predicted_group)
autoplot(cm, type = "heatmap")
pdf(paste("output/figure/",batch_name, "_regular_machine_learning_confusion_matrix.pdf", sep = ""),  width = 8, height = 6)
autoplot(cm, type = "heatmap")
dev.off()
roc_curve <- roc_curve(predictions, Diagnosis,predicted_Diagnosis)
autoplot(roc_curve)
pdf(paste("output/figure/",batch_name, "_regular_machine_learning_roc_curve.pdf", sep = ""))
autoplot(roc_curve)
dev.off()
obj <- roc(predictions$Diagnosis, predictions$predicted_Diagnosis, ci=TRUE, plot =FALSE, levels = c(str_split(batch_name, pattern = "vs")[[1]][1], str_split(batch_name, pattern = "vs")[[1]][2]))
obj$ci
# caret::confusionMatrix(predictions$predicted_group, predictions$Diagnosis, positive = str_split(batch_name, pattern = "vs")[[1]][1])

```

### Save

```{r warning=F, message=F}
  save_models(models, file = paste("my_models_",batch_name,".RDS", sep = ""))

```




# AD vs aMCI

```{r }
batch_name <- "ADvsaMCI"
metat_group <- subset(metat, Diagnosis != "NC")
phy_core <- phy_core_all
sample_data(phy_core) <- metat_group
phy_core <- microbiome::transform(phy_core, "clr") # clr transformation
otu_tab <- scale(t(abundances(phy_core))) %>% data.frame()
asv_to_bact <-tax_table(phy_core) %>% data.frame()
asv_to_bact <- paste(asv_to_bact$Family, asv_to_bact$Genus, row.names(asv_to_bact), sep = "")
asv_to_bact <- abbreviate_taxa_names(asv_to_bact)
colnames(otu_tab) <- asv_to_bact
otu_tab$SampleID <- row.names(otu_tab)
new_table <- dplyr::select(metat_group, "sample_GV", "Diagnosis", "Gender", "Age")
new_otu_table <- merge(x = otu_tab, y = new_table, by.x = "SampleID", by.y = "sample_GV", all=TRUE) %>%
                dplyr::select("SampleID", "Diagnosis", "Gender", "Age", everything()) %>% subset(select = -SampleID)
new_otu_table$Diagnosis <- as.factor(new_otu_table$Diagnosis)
new_otu_table$Diagnosis <- relevel(new_otu_table$Diagnosis ,str_split(batch_name, pattern = "vs")[[1]][1])
write.table(new_otu_table, file = "output/table/AD_vs_aMCI_tss.csv", sep = ",", row.names = FALSE)
```


## Train biomarker using package hsstan

```{r warning=F, message=F}
 
options(mc.cores=10)
hs.base <- hsstan(new_otu_table, Diagnosis ~ Age + Gender, penalized = "")
hs.biom <- hsstan(new_otu_table, Diagnosis ~ Age + Gender, penalized=colnames(new_otu_table)[4:length(new_otu_table)])
sampler.stats(hs.base)
sampler.stats(hs.biom)
loo(hs.base)
loo(hs.biom)

set.seed(1)
folds <- caret::createFolds(new_otu_table$Diagnosis, k=10, list=FALSE)
cv.base <- kfold(hs.base, folds=folds)
cv.biom <- kfold(hs.biom, folds=folds)
round(posterior_performance(cv.base), 2)
round(posterior_performance(cv.biom), 2)
sel.biom <- projsel(hs.biom)
DT::datatable(sel.biom)
```


## Easy Machine Learning using package healthcareai

```{r warning=F, message=F}
asv_select <- sel.biom$var[3:length(sel.biom$var)]
all_otu_table <- new_otu_table
new_otu_table <- dplyr::select(new_otu_table, "Diagnosis", asv_select)

```


```{r warning=F, message=F}
quick_models <- machine_learn(new_otu_table, outcome = Diagnosis, positive_class = str_split(batch_name, pattern = "vs")[[1]][1])
predictions <- predict(quick_models, outcome_groups = TRUE)
plot(predictions)
pdf(paste("output/figure/",batch_name, "_easy_machine_learning_predictions.pdf", sep = ""), width = 9, height = 6)
plot(predictions)
dev.off()
importance_var <- get_variable_importance(quick_models)
plot(importance_var)
pdf(paste("output/figure/",batch_name, "_easy_machine_learning_variable_importance.pdf", sep = ""), width = 9, height = 7)
plot(importance_var)
dev.off()
write.csv(importance_var, file = "output/table/AD_vs_aMCI_easy_variable_importance.csv", row.names = FALSE)
write.csv(predictions, file = "output/table/AD_vs_aMCI_easy_predictions.csv", row.names = FALSE)
```

#### Confusion matrix and ROC

```{r }
predictions$predicted_group <- relevel(predictions$predicted_group,str_split(batch_name, pattern = "vs")[[1]][1])
cm <- predictions %>% 
  conf_mat(truth = Diagnosis, estimate = predicted_group)
autoplot(cm, type = "heatmap")
pdf(paste("output/figure/",batch_name, "_easy_machine_learning_confusion_matrix.pdf", sep = ""),  width = 8, height = 6)
autoplot(cm, type = "heatmap")
dev.off()
roc_curve <- roc_curve(predictions, Diagnosis,predicted_Diagnosis)
autoplot(roc_curve)
pdf(paste("output/figure/",batch_name, "_easy_machine_learning_roc_curve.pdf", sep = ""))
autoplot(roc_curve)
dev.off()
obj <- roc(predictions$Diagnosis, predictions$predicted_Diagnosis, ci=TRUE, plot =FALSE, levels = c(str_split(batch_name, pattern = "vs")[[1]][1], str_split(batch_name, pattern = "vs")[[1]][2]))
obj$ci
# caret::confusionMatrix(predictions$predicted_group, predictions$Diagnosis, positive = str_split(batch_name, pattern = "vs")[[1]][1])

```

After variable selection using hsstan, The prediction accuracy improved.

## Regular machine learning using package healthcareai

### Data Preparation

```{r warning=F, message=F}

  split_data <- split_train_test(d = new_otu_table,
                               outcome = Diagnosis,
                               p = .8,
                               seed = 84105)

 prepped_training_data <- prep_data(split_data$train, outcome = Diagnosis,
                                   center = TRUE, scale = TRUE,
                                   collapse_rare_factors = FALSE)
# > Training new data prep recipe...
 
models <- tune_models(d = prepped_training_data,
                      outcome = Diagnosis,
                      tune_depth = 25,
                      positive_class = str_split(batch_name, pattern = "vs")[[1]][1],
                      metric = "PR")

evaluate(models, all_models = TRUE)

evalution <- models["glmnet"] 
plot(evalution)
pdf(paste("output/figure/",batch_name, "_regular_machine_learning_evaluation.pdf", sep = ""),width = 8, height = 6)
plot(evalution)
dev.off()
```

### Model Interpretation

#### Interpret

```{r warning=F, message=F}
  interpretation <- interpret(models)
plot(interpretation)
pdf(paste("output/figure/",batch_name, "_regular_machine_learning_interpret.pdf", sep = ""),width = 8, height = 6)
plot(interpretation)
dev.off()
# > Warning in interpret(models): Interpreting glmnet model, but Random Forest
# > performed best in cross-validation and will be used to make predictions. To use
# > the glmnet model for predictions, extract it with x['glmnet'].

```

#### Variable Importance

```{r warning=F, message=F}
  get_variable_importance <- get_variable_importance(models)
  plot(get_variable_importance)
  pdf(paste("output/figure/",batch_name, "_regular_machine_learning_variable_importance.pdf", sep = ""), width = 9, height = 7)
  plot(get_variable_importance)
  dev.off()
```


### Prediction

```{r warning=F, message=F}
  predictions <-
  predict(models,
          split_data$test,
          outcome_groups = TRUE
  )
# > Prepping data based on provided recipe
importance_var2 <- get_variable_importance(models)
write.csv(importance_var2, file = "output/table/AD_vs_aMCI_regular_variable_importance.csv", row.names = FALSE)
write.csv(predictions, file = "output/tableAD_vs_aMCI_regular_predictions.csv", row.names = FALSE)
plot(predictions)
pdf(paste("output/figure/",batch_name, "_regular_machine_learning_predictions.pdf", sep = ""), width = 9, height = 6)
plot(predictions)
dev.off()

```

#### Confusion matrix and ROC

```{r }
predictions$predicted_group <- relevel(predictions$predicted_group,str_split(batch_name, pattern = "vs")[[1]][1])
cm <- predictions %>% 
  conf_mat(truth = Diagnosis, estimate = predicted_group)
autoplot(cm, type = "heatmap")
pdf(paste("output/figure/",batch_name, "_regular_machine_learning_confusion_matrix.pdf", sep = ""),  width = 8, height = 6)
autoplot(cm, type = "heatmap")
dev.off()
roc_curve <- roc_curve(predictions, Diagnosis,predicted_Diagnosis)
autoplot(roc_curve)
pdf(paste("output/figure/",batch_name, "_regular_machine_learning_roc_curve.pdf", sep = ""))
autoplot(roc_curve)
dev.off()
obj <- roc(predictions$Diagnosis, predictions$predicted_Diagnosis, ci=TRUE, plot =FALSE, levels = c(str_split(batch_name, pattern = "vs")[[1]][1], str_split(batch_name, pattern = "vs")[[1]][2]))
obj$ci
# caret::confusionMatrix(predictions$predicted_group, predictions$Diagnosis, positive = str_split(batch_name, pattern = "vs")[[1]][1])

```

### Save

```{r warning=F, message=F}
  save_models(models, file = paste("my_models_",batch_name,".RDS", sep = ""))
  save.image()
```


